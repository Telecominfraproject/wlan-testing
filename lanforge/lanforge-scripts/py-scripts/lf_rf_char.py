#!/usr/bin/env python3

"""
NAME: lf_rf_test.py

PURPOSE:
RF Characteristics Test

SETUP:
There need to be a vAP in a Virtual Router  on LANforge , goal is to eventually have autogenerated

EXAMPLE:

./lf_rf_char.py --lf_mgr 192.168.0.104 --lf_port 8080 --lf_user lanforge --lf_passwd lanforge \
    --vap_port 1.1.vap3 --vap_radio 1.1.wiphy3 --vap_channel 36 --vap_antenna 0 \
    --log_level debug --debug --duration 10s --polling_interval 1s --frame 1400 \
    --frame_interval .01


COPYRIGHT:
    Copyright 2022 Candela Technologies Inc
    License: Free to distribute and modify. LANforge systems must be licensed.

INCLUDE_IN_README
"""

# TODO:  Done, Set report timer on vap and radios to 1 sec, possibly smaller.
# TODO:  Done, Enable extra tx and rx stats on the radios ,

from pprint import pformat
from pprint import pprint
import argparse
import sys
import os
import logging
import importlib
import datetime
import pandas as pd
import json
import traceback
import csv
import time
import re
import platform
import subprocess
import numpy as np

sys.path.append(os.path.join(os.path.abspath(__file__ + "../../../")))
lanforge_api = importlib.import_module("lanforge_client.lanforge_api")
from lanforge_client.lanforge_api import LFSession
from lanforge_client.lanforge_api import LFJsonCommand
from lanforge_client.lanforge_api import LFJsonQuery

LFUtils = importlib.import_module("py-json.LANforge.LFUtils")

lf_json_api = importlib.import_module("py-scripts.lf_json_api")
lf_report = importlib.import_module("py-scripts.lf_report")
lf_graph = importlib.import_module("py-scripts.lf_graph")
lf_bar_graph = lf_graph.lf_bar_graph
lf_bar_line_graph = lf_graph.lf_bar_line_graph
lf_line_graph = lf_graph.lf_line_graph

lf_kpi_csv = importlib.import_module("py-scripts.lf_kpi_csv")
lf_logger_config = importlib.import_module("py-scripts.lf_logger_config")

realm = importlib.import_module("py-json.realm")
Realm = realm.Realm


logger = logging.getLogger(__name__)


if sys.version_info[0] != 3:
    print("This script requires Python 3")
    exit(1)


# RF Characteristics Test
# TODO try to have utilites in own file
class lf_rf_char(Realm):
    def __init__(self,
                 lf_mgr=None,
                 lf_port=None,
                 lf_user=None,
                 lf_passwd=None,
                 debug=False
                 ):
        self.lf_mgr = lf_mgr
        self.lf_port = lf_port
        self.lf_user = lf_user
        self.lf_passwd = lf_passwd
        self.debug = debug
        self.vap_port = ''
        self.radio = ''
        self.vap = ''
        self.port = ''
        self.shelf = ''
        self.resource = ''
        self.duration = ''
        self.polling_interval = ''
        self.frame = ''
        self.frame_interval = ''
        self.gen_endpoint = ''
        self.cx_state = ''

        # create api_json
        self.json_vap_api = lf_json_api.lf_json_api(lf_mgr=self.lf_mgr,
                                                    lf_port=self.lf_port,
                                                    lf_user=self.lf_user,
                                                    lf_passwd=self.lf_passwd)

        self.json_rad_api = lf_json_api.lf_json_api(lf_mgr=self.lf_mgr,
                                                    lf_port=self.lf_port,
                                                    lf_user=self.lf_user,
                                                    lf_passwd=self.lf_passwd)

        # create a session
        # self.session = LFSession(lfclient_url="http://{lf_mgr}:{lf_port}".format(lf_mgr=self.lf_mgr, lf_port=self.lf_port),
        self.session = LFSession(lfclient_url="http://%s:8080" % self.lf_mgr,
                                 debug=debug,
                                 connection_timeout_sec=4.0,
                                 stream_errors=True,
                                 stream_warnings=True,
                                 require_session=True,
                                 exit_on_error=True)
        # type hinting
        self.command: LFJsonCommand
        self.command = self.session.get_command()
        self.query: LFJsonQuery
        self.query = self.session.get_query()

        # vap configuration
        self.shelf = ''
        self.resource = ''
        self.port_name = ''
        self.vap_radio = ''
        self.vap_channel = ''
        self.vap_antenna = ''

        # get dut information
        self.lf_command = ''
        self.dut_mac = ''
        self.dut_ip = ''
        self.dut_hostname = ''

        # tx data
        self.tx_interval = []
        self.tx_pkts = []
        self.tx_retries = []
        self.tx_failed = []

        # RSSI calculation
        self.rssi_signal = []
        self.rssi_1 = []
        self.rssi_2 = []
        self.rssi_3 = []
        self.rssi_4 = []
        self.rssi_1_count = 0
        self.rssi_2_count = 0
        self.rssi_3_count = 0
        self.rssi_4_count = 0

        # logging
        self.debug = debug

    def dut_info(self):
        self.json_vap_api.request = 'stations'
        json_stations = []
        sta_ap = ""

        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        vap_eid = "%s.%s.%s" % (self.shelf, self.resource, self.port_name)

        try:
            # does not need specific port information
            json_stations, *nil = self.json_vap_api.get_request_stations_information()

            self.dut_mac = json_stations['station']['station bssid']
            sta_ap = json_stations['station']['ap']
            logger.info("DUT MAC: {mac}".format(mac=self.dut_mac))
        except BaseException:
            # Maybe we have multiple stations showing up on multiple VAPs...find the first one that matches our vap.
            print("Looking for vap-eid: %s" % (vap_eid))
            try:
                for s in json_stations['stations']:
                    keys = list(s.keys())
                    vals = s[keys[0]]

                    if vals['ap'] == vap_eid:
                        sta_ap = vap_eid
                        self.dut_mac = vals['station bssid']
                        print("found sta, ap: %s  mac: %s" % (sta_ap, self.dut_mac))
                        break
            except BaseException:
                print("waiting on stations")
                pass

            if sta_ap == "":
                logger.error("Stations table not as expected:")
                pprint(json_stations)
                return False

        # Make sure the station is on correct IP vap
        if (sta_ap != vap_eid):
            logger.error("Detected STA on AP: %s, expected it to be on AP: %s" % (sta_ap, vap_eid))
            return False

        # get the IP from port mode
        summary_output = ""
        errs_warns = []
        self.command.post_probe_port(shelf=1,
                                     resource=self.resource,
                                     port=self.port_name,
                                     key="probe_port.quiet.1.{}.{}".format(self.resource, self.port_name),
                                     suppress_related_commands=True)
        # response = self.query.get_probe(eid_list=[self.vap], errors_warnings=errs_warns, wait_sec=1, debug=True)
        response = self.query.json_get("/probe/1/{}/{}".format(self.resource, self.port_name),
                                       wait_sec=1, debug=True, errors_warnings=errs_warns)

        dut_ip = ''
        dut_mac = ''
        dut_hostname = ''
        search_dhcp_lease = False
        search_equals = False
        for line in summary_output.splitlines():
            if (line.startswith("DHCPD-Lease-File-Contents")):
                search_equals = True
                continue

            if (search_equals and line.startswith("=========")):
                search_dhcp_lease = True
                continue

            if (search_dhcp_lease):
                pat = "(\\S+)\\s+(\\S+)\\s+(\\S+)"
                m = re.search(pat, line)
                if (m is not None):
                    dut_mac = m.group(1)
                    dut_ip = m.group(2)
                    dut_hostname = m.group(3)
                else:
                    pat = "(\\S+)\\s+(\\S+)"
                    m = re.search(pat, line)
                    if (m is not None):
                        dut_mac = m.group(1)
                        dut_ip = m.group(2)
            # there should only be one connection

        logger.debug("probe mac:[{mac}] ip:[{ip}]".format(mac=dut_mac, ip=dut_ip))
        if dut_mac != self.dut_mac:
            logger.error("mac mismatch test cannot continue: probe mac:[{mac}] stations mac:[{station_mac}]".
                         format(mac=dut_mac, station_mac=self.dut_mac))
            return False

        self.dut_ip = dut_ip
        self.dut_hostname = dut_hostname

        return True

    def clear_dhcp_lease(self):
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        # may have to add extra to
        extra = 'dhcp_leases'
        self.command.post_clear_port_counters(shelf=self.shelf,
                                              resource=self.resource,
                                              port=self.port_name,
                                              extra=extra)

    def clear_port_counters(self):
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        # may have to add extra to
        self.command.post_clear_port_counters(shelf=self.shelf,
                                              resource=self.resource,
                                              port=self.port_name,
                                              extra=None)

        # Clear radio stats too
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_radio)
        self.command.post_clear_port_counters(shelf=self.shelf,
                                              resource=self.resource,
                                              port=self.port_name,
                                              extra=None)
    # ./lf_generic_ping.pl --mgr 192.168.0.104 --resource 1 --dest 10.10.10.4 -i vap3 --cmd 'lfping -s 1400 -i 0.01 -I vap3 10.10.10.4

    # set_port 1 1 vap3 NA NA NA NA NA NA NA NA NA 32768 5000 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    # set_port 1 1 vap3 NA NA NA NA NA NA NA NA NA 32768 1000
    def set_port_report_timer(self, port=None, milliseconds=1000):
        if port is not None:
            self.port = port
            self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.port)
        self.command.post_set_port(shelf=self.shelf,
                                   resource=self.resource,
                                   port=self.port_name,
                                   interest=32768,
                                   report_timer=int(milliseconds),
                                   debug=self.debug)

    # enable extra_rxstatus extra_txstatus
    def set_wifi_radio(self, radio=None, flags_list=[]):
        if radio is not None:
            self.radio = radio
            self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_radio)

        flag_val = 0
        # flag_val = LFPost.set_flags(SetWifiRadioFlags0, flag_names=['extra_rxstatus', 'extra_tx_status'])
        flag_val = self.command.set_flags(self.command.SetWifiRadioFlags, flag_val, flag_names=flags_list)
        self.command.post_set_wifi_radio(shelf=self.shelf,
                                         resource=self.resource,
                                         radio=self.port_name,
                                         flags=flag_val,
                                         flags_mask=flag_val,
                                         debug=self.debug)

    def generic_ping(self):
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        self.gen_endpoint = "CX_lfping_{port_name}".format(port_name=self.port_name)

        # need to change the current working director to run lf_generic_ping.pl
        cwd_orig = os.getcwd()
        logger.info("Current Working Directory is :{cwd}".format(cwd=cwd_orig))
        os.chdir('../')
        cwd_new = os.getcwd()
        logger.info("Move up one dir Working Directory is :{cwd}".format(cwd=cwd_new))

        self.lf_command = ["./lf_generic_ping.pl", "--mgr", self.lf_mgr, "--resource", str(self.resource), "--dest", self.dut_ip,
                           "-i", self.port_name, "--cmd", 'lfping -s {frame} -i {frame_interval} -I {port_name} {dut_ip}'.
                           format(frame=self.frame, frame_interval=self.frame_interval, port_name=self.port_name, dut_ip=self.dut_ip)]
        logger.debug("lf_generic_ping.pl : {cmd}".format(cmd=self.lf_command))
        summary_output = ''

        summary = subprocess.Popen(self.lf_command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)

        for line in iter(summary.stdout.readline, ''):
            logger.debug(line)
            summary_output += line
            # sys.stdout.flush() # please see comments regarding the necessity of this line
        summary.wait()
        logger.debug(summary_output)  # .decode('utf-8', 'ignore'))
        os.chdir(cwd_orig)
        cwd_final = os.getcwd()
        logger.info("Current Working Directory is :{cwd}".format(cwd=cwd_final))

    # for updating the ping information
    # ./lf_generic_ping.pl --mgr 192.168.0.104 --resource 1 --dest 10.10.10.4 -i vap3 --cmd 'lfping -s 1400 -i 0.01 -I vap3 10.10.10.4'
    # add_gen_endp

    # TODO not working yet using perl command
    # TODO pass port
    def add_gen_endp(self):
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        # cross connects prepend CX
        self.gen_endpoint = "CX_lfping_{port_name}".format(port_name=self.port_name)
        self.command.post_add_gen_endp(
            alias=self.gen_endpoint,
            port=self.port_name,
            resource=self.resource,
            shelf=self.shelf,
            p_type='gen_generic',   # gen_generic is default
            debug=self.debug
        )

    # TODO not working yet using perl command
    # TODO pass port
    # set_gen_cmd
    def set_gen_cmd(self):
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_port)
        lf_command = "lfping '-s {frame} -i {frame_interval} -I {port_name} {ip}".format(
            frame=self.frame, frame_interval=self.frame_interval, port_name=self.port_name, ip=self.dut_ip)
        self.command.post_set_gen_cmd(
            command=lf_command,
            name=self.gen_endpoint,
            debug=self.debug)

    # set_cx_state

    def set_cx_state(self):
        self.command.post_set_cx_state(cx_name=self.gen_endpoint,
                                       cx_state=self.cx_state,
                                       test_mgr='all',
                                       debug=self.debug)

    def modify_radio(self):
        self.shelf, self.resource, self.port_name, *nil = LFUtils.name_to_eid(self.vap_radio)
        self.command.post_set_wifi_radio(
            shelf=self.shelf,
            resource=self.resource,
            radio=self.port_name,
            antenna=self.vap_antenna,
            channel=self.vap_channel,
            debug=self.debug)
        self.command.post_reset_port(shelf=self.shelf,
                                     resource=self.resource,
                                     port=self.port_name)

    def start(self):
        # first read with
        self.json_vap_api.port = self.vap_port
        self.json_vap_api.update_port_info()
        self.json_vap_api.csv_mode = 'write'
        self.json_vap_api.update_csv_mode()
        self.json_vap_api.request = 'port'

        self.json_rad_api.port = self.vap_radio
        self.json_rad_api.update_port_info()
        self.json_rad_api.csv_mode = 'write'
        self.json_rad_api.update_csv_mode()
        self.json_rad_api.request = 'port'

        self.tx_interval = []
        self.tx_interval_time = []
        self.tx_pkts = []
        self.tx_retries = []
        self.tx_failed = []

        self.rssi_signal = []
        self.rssi_1 = []
        self.rssi_2 = []
        self.rssi_3 = []
        self.rssi_4 = []
        self.rssi_1_count = 0
        self.rssi_2_count = 0
        self.rssi_3_count = 0
        self.rssi_4_count = 0

        # create lfping generic
        '''
        # Using lanforge_api
        logger.info("create generic endpoint")
        self.add_gen_endp()
        logger.info("set frame {frame} frame_interval {interval}".format(frame=self.frame,interval=self.frame_interval))
        self.set_gen_cmd()
        '''
        # use the lf_generic_ping.pl
        self.generic_ping()
        logger.info("start the lfping cx traffic frame: {frame} frame_interval: {frame_interval}".format(frame=self.frame, frame_interval=self.frame_interval))
        # TODO understand when data is read
        # This needs to be removed
        time.sleep(1)

        self.cx_state = 'RUNNING'  # RUNNING< SWITCHB, QUIESCE, STOPPED, or DELETED
        self.set_cx_state()

        logger.info("clear port counters")
        self.clear_port_counters()

        jason_vap_port_stats, *nil = self.json_vap_api.get_request_port_information(port=self.vap_port)
        tx_pkts_previous = 0
        tx_retries_previous = 0

        self.json_vap_api.csv_mode = 'append'
        self.json_vap_api.update_csv_mode()

        cur_time = datetime.datetime.now()
        end_time = self.parse_time(self.duration) + cur_time
        polling_interval_milliseconds = self.duration_time_to_milliseconds(self.polling_interval)
        sleep_interval = (polling_interval_milliseconds/1000)/2
        interval = 0
        # initialize time stamps
        json_vap_port_stats, *nil = self.json_vap_api.get_request_port_information(port=self.vap_port)
        current_time_stamp = json_vap_port_stats["interface"]["time-stamp"]
        previous_time_stamp = current_time_stamp
        tx_pkts_previous = json_vap_port_stats["interface"]["tx pkts"]
        tx_retries_previous = json_vap_port_stats["interface"]["wifi retries"]
        while cur_time < end_time:
            interval_time = cur_time + datetime.timedelta(milliseconds=polling_interval_milliseconds)

            # check the port time stamp to see if data changed
            # check 1/2 polling interval
            while cur_time < interval_time:
                cur_time = datetime.datetime.now()
                # read the current time
                time.sleep(sleep_interval)
                json_vap_port_stats, *nil = self.json_vap_api.get_request_port_information(port=self.vap_port)
                current_time_stamp = json_vap_port_stats["interface"]["time-stamp"]
                if current_time_stamp != previous_time_stamp:
                    logger.debug("new TX stats: time_stamp {time} previous_time_stamp {pre_time}".format(time=current_time_stamp, pre_time=previous_time_stamp))
                    previous_time_stamp = current_time_stamp
                    break
                # Here check if the time stamp has changed

            # json_vap_port_stats, *nil = self.json_vap_api.get_request_port_information(port=self.vap_port)
            interval += float(polling_interval_milliseconds) / 1000
            self.tx_interval.append(interval)
            current_time = current_time_stamp.split()
            self.tx_interval_time.append(current_time[1])
            # print(json_vap_port_stats["interface"]["tx pkts"])
            self.tx_pkts.append(json_vap_port_stats["interface"]["tx pkts"] - tx_pkts_previous)
            tx_pkts_previous = json_vap_port_stats["interface"]["tx pkts"]
            self.tx_retries.append(json_vap_port_stats["interface"]["wifi retries"] - tx_retries_previous)
            tx_retries_previous = json_vap_port_stats["interface"]["wifi retries"]
            self.tx_failed.append(round(json_vap_port_stats["interface"]["tx-failed %"], 2))
            # calculated the transmitted packets compared to number of retries

            # take samples of RSSI
            self.json_vap_api.request = 'stations'
            # port not needed for all
            json_stations, *nil = self.json_vap_api.get_request_stations_information()
            logger.info("json_stations {json}".format(json=pformat(json_stations)))
            try:
                self.rssi_signal.append(json_stations['station']['signal'])
                chain_rssi_str = json_stations['station']['chain rssi']
                chain_rssi = chain_rssi_str.split(',')
            except BaseException:
                # Maybe we have multiple stations showing up on multiple VAPs...find the first one that matches our vap.
                # pprint(json_stations)
                # This should give us faster lookup if I knew how to use it.
                #sta_key = "0.0.0.%s"%(self.dut_mac)
                #pprint("key: %s"%(sta_key))
                for s in json_stations['stations']:
                    keys = list(s.keys())
                    vals = s[keys[0]]
                    if vals['station bssid'] == self.dut_mac:
                        self.rssi_signal.append(int(vals['signal'].lstrip()))
                        chain_rssi_str = vals['chain rssi']
                        chain_rssi = chain_rssi_str.split(',')
                        break

            logger.info("RSSI chain length {chain}".format(chain=len(chain_rssi)))
            if len(chain_rssi) == 1:
                self.rssi_1.append(int(chain_rssi[0].lstrip()))
                self.rssi_2.append(np.nan)
                self.rssi_3.append(np.nan)
                self.rssi_4.append(np.nan)
                self.rssi_1_count = self.rssi_1_count + 1
            elif len(chain_rssi) == 2:
                self.rssi_1.append(int(chain_rssi[0].lstrip()))
                self.rssi_2.append(int(chain_rssi[1].lstrip()))
                self.rssi_3.append(np.nan)
                self.rssi_4.append(np.nan)
                self.rssi_2_count = self.rssi_2_count + 1
            elif len(chain_rssi) == 3:
                self.rssi_1.append(int(chain_rssi[0].lstrip()))
                self.rssi_2.append(int(chain_rssi[1].lstrip()))
                self.rssi_3.append(int(chain_rssi[2].lstrip()))
                self.rssi_4.append(np.nan)
                self.rssi_3_count = self.rssi_3_count + 1
            elif len(chain_rssi) == 4:
                self.rssi_1.append(int(chain_rssi[0].lstrip()))
                self.rssi_2.append(int(chain_rssi[1].lstrip()))
                self.rssi_3.append(int(chain_rssi[2].lstrip()))
                self.rssi_4.append(int(chain_rssi[3].lstrip()))
                self.rssi_4_count = self.rssi_4_count + 1

        self.json_vap_api.csv_mode = 'write'
        self.json_vap_api.update_csv_mode()

        # TODO make the get_request more generic just set the request
        self.json_rad_api.request = 'wifi-stats'
        # Read the vap device stats, it will also be able to report underlying radio stats as needed.
        json_wifi_stats, *nil = self.json_rad_api.get_request_wifi_stats_information(port=self.vap_port)
        #print("wifi-stats output, vap-radio: %s radio port name %s:"%(self.vap_radio, self.json_api.port_name))
        # pprint(json_wifi_stats)

        # Stop Traffic
        self.cx_state = 'STOPPED'  # RUNNING< SWITCHB, QUIESCE, STOPPED, or DELETED
        self.set_cx_state()

        return jason_vap_port_stats, json_wifi_stats

        # gather interval samples read stations to get RX Bytes, TX Bytes, TX Retries,

        # read the extended mgr tab to get rx tx MCS, NSS

    def read_wifi_stats(self):
        pass

    def read_stations(self):
        pass


def main():
    # arguments
    parser = argparse.ArgumentParser(
        prog='lf_rf_char.py',
        formatter_class=argparse.RawTextHelpFormatter,
        epilog='''\
            lf_rf_char.py : RF Characteristics test
            ''',
        description='''\
lf_rf_char.py
-----------

Summary :
---------

Gather Tx and Rx RF Characteristic for a specific duration and polling interval

Example :
---------

./lf_rf_char.py --lf_mgr 192.168.0.104 --lf_port 8080 --lf_user lanforge --lf_passwd lanforge \
    --vap_port 1.1.vap3 --vap_radio 1.1.wiphy3 --vap_channel 36 --vap_antenna 0 \
    --log_level debug --debug --duration 10s --polling_interval 1s --frame 1400 \
    --frame_interval .01

for individual command telnet <lf_mgr> 4001 ,  then can execute cli commands
            ''')
    # LANforge configuration
    parser.add_argument("--lf_mgr", type=str, help="address of the LANforge GUI machine (localhost is default)", default='localhost')
    parser.add_argument("--lf_port", help="IP Port the LANforge GUI is listening on (8080 is default)", default=8080)
    parser.add_argument("--lf_user", type=str, help="user: lanforge", default='lanforge')
    parser.add_argument("--lf_passwd", type=str, help="passwd: lanforge", default='lanforge')
    parser.add_argument("--vap_port", type=str, help=" port : 1.1.vap3  provide full eid  (endpoint id", required=True)
    parser.add_argument("--vap_radio", type=str, help=" --vap_radio wiphy0", required=True)
    parser.add_argument("--vap_channel", type=str, help=" --vap_channel '36'  channel of the radio e.g. 6 (2.4G) , 36 (5G), ")
    parser.add_argument("--vap_antenna", help='number of spatial streams: 0 Diversity (All), 1 Fixed-A (1x1), 4 AB (2x2), 7 ABC (3x3), 8 ABCD (4x4), 9 (8x8)')

    # Reporting Configuration
    parser.add_argument('--local_lf_report_dir', help='--local_lf_report_dir override the report path, primary use when running test in test suite', default="")
    parser.add_argument("--test_rig", default="lanforge",
                        help="test rig for kpi.csv, testbed that the tests are run on")
    parser.add_argument("--test_tag", default="kpi_generation",
                        help="test tag for kpi.csv,  test specific information to differenciate the test")
    parser.add_argument("--dut_hw_version", default="",
                        help="dut hw version for kpi.csv, hardware version of the device under test")
    parser.add_argument("--dut_sw_version", default="",
                        help="dut sw version for kpi.csv, software version of the device under test")
    parser.add_argument("--dut_model_num", default="",
                        help="dut model for kpi.csv,  model number / name of the device under test")
    parser.add_argument("--dut_serial_num", default="",
                        help="dut serial num for kpi.csv,  model serial number ")

    parser.add_argument("--test_priority", default="95",
                        help="dut model for kpi.csv,  test-priority is arbitrary number")
    parser.add_argument("--test_id", default="kpi_unit_test", help="test-id for kpi.csv,  script or test name")
    parser.add_argument("--csv_outfile", default="lf_rf_char", help=" csv outfile")

    # Logging Configuration
    parser.add_argument('--log_level', default=None, help='Set logging level: debug | info | warning | error | critical')
    parser.add_argument("--lf_logger_config_json", help="--lf_logger_config_json <json file> , json configuration of logger")
    parser.add_argument('--debug', help='Legacy debug flag', action='store_true')

    # Test Configuration
    parser.add_argument('--desc', help="--desc <test description> , if not provided will section not printed")
    parser.add_argument('--polynomial', help="--polynomial store_true , show polynomial lines on retries graph", action="store_true")
    parser.add_argument('--interpolate', help="--interpolate store_true , show interpolation on retries graph", action="store_true")
    parser.add_argument('--duration', help="--duration <seconds>", default='20s')
    parser.add_argument('--polling_interval', help="--polling_interval <h m s ms>", default='1000ms')
    parser.add_argument('--frame', help="--frame <bytes>  , e.g. --frame 1400", default='1400')
    parser.add_argument('--frame_interval', help="--frame_interval <fractions of second>  , e.g. --frame_interval .01 ", default='.01')

    args = parser.parse_args()

    # set up logger
    logger_config = lf_logger_config.lf_logger_config()

    # set the logger level to debug
    if args.log_level:
        logger_config.set_level(level=args.log_level)

    # lf_logger_config_json will take presidence to changing debug levels
    if args.lf_logger_config_json:
        # logger_config.lf_logger_config_json = "lf_logger_config.json"
        logger_config.lf_logger_config_json = args.lf_logger_config_json
        logger_config.load_lf_logger_config()

    if not args.vap_radio:
        logger.info("No radio name provided")
        exit(1)

    # Gather data for test reporting
    # for kpi.csv generation
    logger.info("read in command line paramaters")
    local_lf_report_dir = args.local_lf_report_dir
    test_rig = args.test_rig
    test_tag = args.test_tag
    dut_hw_version = args.dut_hw_version
    dut_sw_version = args.dut_sw_version
    dut_model_num = args.dut_model_num
    dut_serial_num = args.dut_serial_num
    # test_priority = args.test_priority  # this may need to be set per test
    test_id = args.test_id

    # Create report, when running with the test framework (lf_check.py)
    # results need to be in the same directory
    logger.info("configure reporting")
    if local_lf_report_dir != "":
        report = lf_report.lf_report(
            _path=local_lf_report_dir,
            _results_dir_name="rf_char",
            _output_html="rf_char.html",
            _output_pdf="rf_char.pdf")
    else:
        report = lf_report.lf_report(
            _results_dir_name="rf_characteristics_test",
            _output_html="rf_char.html",
            _output_pdf="rf_char.pdf")

    kpi_path = report.get_report_path()
    logger.info("Report and kpi_path :{kpi_path}".format(kpi_path=kpi_path))

    kpi_csv = lf_kpi_csv.lf_kpi_csv(
        _kpi_path=kpi_path,
        _kpi_test_rig=test_rig,
        _kpi_test_tag=test_tag,
        _kpi_dut_hw_version=dut_hw_version,
        _kpi_dut_sw_version=dut_sw_version,
        _kpi_dut_model_num=dut_model_num,
        _kpi_dut_serial_num=dut_serial_num,
        _kpi_test_id=test_id)

    if args.csv_outfile is not None:
        current_time = time.strftime("%Y-%m-%d-%H-%M-%S", time.localtime())
        csv_outfile = "{}_{}_lf_rf_char.csv".format(
            args.csv_outfile, current_time)
        csv_outfile = report.file_add_path(csv_outfile)
        logger.info("csv output file : {}".format(csv_outfile))

    # begin creating the report
    report.set_title("RF Characteristics Test")
    report.build_banner_left()
    report.start_content_div2()
    report.set_obj_html("Objective", "RF Characteristics Test: Report RX and TX characteristics")
    report.build_objective()

    if args.desc:
        report.set_desc_html("Test Description", "{desc}".format(desc=args.desc))
        report.build_description()

    # Set up the RF Characteristic test
    logger.info("Configure RF Characteristic test")
    rf_char = lf_rf_char(lf_mgr=args.lf_mgr,
                         lf_port=args.lf_port,
                         lf_user=args.lf_user,
                         lf_passwd=args.lf_passwd,
                         debug=args.debug)

    # TODO need to get the DUT IP and put into test_input infor
    rf_char.vap_radio = args.vap_radio
    rf_char.vap_channel = args.vap_channel
    rf_char.vap_antenna = args.vap_antenna
    rf_char.vap_port = args.vap_port

    logger.info("clear dhcp leases")
    rf_char.clear_dhcp_lease()

    # modify and reset
    rf_char.modify_radio()

    try_count = 0
    while try_count < 100:
        if rf_char.dut_info():
            break
        print("Could not query DUT info from DHCP, waiting %s/100" % (try_count))
        time.sleep(3)
        try_count = try_count + 1

    dut_mac = rf_char.dut_mac
    dut_ip = rf_char.dut_ip

    test_setup_info = {
        "DUT Name": rf_char.dut_hostname,
        "DUT Model": args.dut_model_num,
        "DUT Hardware Version": args.dut_hw_version,
        "DUT Software Version": args.dut_sw_version,
        "DUT Serial Number": args.dut_serial_num,
        "DUT MAC": dut_mac,
        "DUT IP": dut_ip
    }

    report.set_table_title("Device Under Test Information")
    report.build_table_title()
    report.test_setup_table(value="Device Under Test", test_setup_data=test_setup_info)

    # Set the report timer
    # use the duration in seconds to set the report timer
    # TODO call only once
    polling_interval_milliseconds = rf_char.duration_time_to_milliseconds(args.polling_interval)
    # polling_interval_milliseconds = polling_interval_seconds*1000
    rf_char.set_port_report_timer(port=args.vap_port, milliseconds=polling_interval_milliseconds)
    rf_char.set_port_report_timer(port=args.vap_radio, milliseconds=polling_interval_milliseconds)

    flags_list = ['extra_rxstatus', 'extra_txstatus']

    rf_char.set_wifi_radio(radio=args.vap_radio, flags_list=flags_list)

    test_input_info = {
        "LANforge ip": args.lf_mgr,
        "LANforge port": args.lf_port,
        "Test Duration": args.duration,
        "Polling Interval": args.polling_interval,
        "GUI Report Interval (ms) vap and vap radio": str(polling_interval_milliseconds),
        "vAP Channel": args.vap_channel
    }

    report.set_table_title("Test Configuration")
    report.build_table_title()
    report.test_setup_table(value="Test Configuration", test_setup_data=test_input_info)

    # Start traffic : Currently manually done
    rf_char.clear_port_counters()

    rf_char.duration = args.duration
    rf_char.polling_interval = args.polling_interval
    logger.debug("frame size {frame}".format(frame=args.frame))
    rf_char.frame = args.frame
    rf_char.frame_interval = args.frame_interval

    # run the test
    json_port_stats, json_wifi_stats, *nil = rf_char.start()

    # sort the values when in a list
    def num_sort(strn):
        # getting number using isdigit() and split()
        computed_num = [ele for ele in strn[0].split('_') if ele.isdigit()]
        # assigning lowest weightage to strings
        # with no numbers
        if len(computed_num) > 0:
            return int(computed_num[0])
        return -1

    def length_sort(strn):
        return len(strn[0])

    # get dataset for the radio
    wifi_stats_json = json_wifi_stats[args.vap_port]

    # transmitted packets per polling interval
    tx_pkts = rf_char.tx_pkts
    tx_retries = rf_char.tx_retries
    tx_failed = rf_char.tx_failed
    tx_interval = rf_char.tx_interval
    tx_interval_time = rf_char.tx_interval_time

    # TX pkts, TX retries,  TX Failed %
    report.set_table_title("TX pkts , TX retries, TX Failed %")
    report.build_table_title()

    df_tx_info = pd.DataFrame({" Time Interval (s) ": [ti for ti in tx_interval], " Time ": [k for k in tx_interval_time], " TX Packets ": [i for i in tx_pkts],
                               " TX Retries ": [j for j in tx_retries], " TX Failed % ": [m for m in tx_failed]})

    report.set_table_dataframe(df_tx_info)
    report.build_table()

    # Write out csv file
    report.set_csv_filename("tx_pkts_tx_retries_tx_failed.csv")
    report.write_dataframe_to_csv()

    # lf_bar_line_graph
    # failed %
    graph = lf_bar_line_graph(
        _data_set1=[tx_pkts, tx_retries],
        _data_set2=[tx_failed],
        _data_set2_poly=[args.polynomial],
        _data_set2_poly_degree=[3],
        _data_set2_interp1d=[args.interpolate],  # interpolate 1d
        _xaxis_name="Time Interval (s)",
        _y1axis_name="TX Packets",
        _y2axis_name="TX Failed %",
        _xaxis_categories=tx_interval,
        _graph_image_name="TX Info bar line",
        _label1=[" TX Packets ", " TX Retries "],
        _label2=[" TX Failed % "],
        _label2_poly=["% plynomial fit"],
        _label2_interp1d=[" % interpolate"],
        _color1=['blue', 'red'],
        _color2=['orange'],
        _color2_poly=['green'],
        _color2_interp1d=['cyan'],
        _marker=['o'],
        _color_edge='black',
        _figsize=(17, 7),
        _grp_title='TX ',
        _xaxis_step=1,
        _show_bar_value=True,
        _text_font=7,
        _text_rotation=45,
        _xticks_font=7,
        _legend_loc1="upper right",
        _legend_loc2="upper left",
        _legend_box1=(0, 0),
        _legend_box2=(1, 0),
        _legend_ncol=1,
        _legend_fontsize=None,
        _enable_csv=False)

    graph_png = graph.build_bar_line_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # RSSI line graphs
    rssi_signal = rf_char.rssi_signal
    rssi_1 = rf_char.rssi_1
    rssi_2 = rf_char.rssi_2
    rssi_3 = rf_char.rssi_3
    rssi_4 = rf_char.rssi_4
    tx_interval = rf_char.tx_interval
    data_set = [rssi_signal, rssi_1, rssi_2, rssi_3, rssi_4]
    label = ["RSSI Signal", "RSSI 1", "RSSI 2", "RSSI 3", "RSSI 4"]

    report.set_table_title("RSSI Signal, RSSI per chain")
    report.build_table_title()

    # TODO:  There is almost certainly a cleaner way to do this.
    # if (rf_char.rssi_4_count > 0):
    df_rssi_info = pd.DataFrame({" Time Interval (s)": [t for t in tx_interval], " Time ": [it for it in tx_interval_time], " RSSI Signal ": [k for k in rssi_signal], " RSSI 1 ": [i for i in rssi_1],
                                " RSSI 2 ": [j for j in rssi_2], " RSSI 3 ": [m for m in rssi_3], " RSSI 4 ": [l for l in rssi_4]})

    report.set_table_dataframe(df_rssi_info.replace(np.nan, ''))
    report.build_table()

    report.set_csv_filename("rssi.csv")
    report.write_dataframe_to_csv()

    # graph RSSI
    graph = lf_line_graph(
        _data_set=data_set,
        _xaxis_name="Time Interval (s)",
        _yaxis_name="RSSI dBm",
        _reverse_y=False,
        _xaxis_categories=tx_interval,
        _graph_title="RSSI",
        _title_size=16,
        _graph_image_name="rssi",
        _label=label,
        _font_weight='bold',
        _color=['blue', 'orange', 'green', 'red', 'cyan'],
        _figsize=(17, 12),
        _xaxis_step=1,
        _text_font=7,
        _legend_loc="upper left",
        _legend_box=(1, 0),
        _legend_ncol=1
    )

    graph_png = graph.build_line_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve rx data from json for MODE
    rx_mode = []
    rx_mode_value_str = []
    rx_mode_value = []
    rx_mode_value_percent = []
    rx_mode_total_count = 0

    # retrieve each mode value from json
    for iterator in wifi_stats_json:
        if 'rx_mode' in iterator:
            rx_mode.append(iterator)
            rx_mode_value_str.append(str(wifi_stats_json[iterator]))
            rx_mode_value.append(wifi_stats_json[iterator])
            rx_mode_total_count += wifi_stats_json[iterator]

    if rx_mode_total_count == 0:
        logger.warning("Could not find any rx-mode packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for rx_mode_count in rx_mode_value:
            rx_mode_value_percent.append(0)
    else:
        # calculate percentages
        for rx_mode_count in rx_mode_value:
            rx_mode_value_percent.append(round((rx_mode_count / rx_mode_total_count) * 100, 2))

    # manipulate data to sort by length to have
    # CCK is first, the OFDMA, then HT variants, then VHT, the HE
    rx_mode = [s.replace('v_rx_mode_ht', 'v_rx_mode_ht_AAA') for s in rx_mode]
    rx_mode = [s.replace('v_rx_mode_vht', 'v_rx_mode_vht_AAA') for s in rx_mode]
    rx_mode = [s.replace('v_rx_mode_he', 'v_rx_mode_he_AAA') for s in rx_mode]

    # rx_mode.sort(key=length_sort)
    logger.debug("Before sort rx mode: {rx_mode} : {rx_mode_value_str} : {rx_mode_value} : {rx_mode_value_percent}".
                 format(rx_mode=rx_mode, rx_mode_value_str=rx_mode_value_str, rx_mode_value=rx_mode_value, rx_mode_value_percent=rx_mode_value_percent))

    # see rx_mcs for details
    rx_mode, rx_mode_value_str, rx_mode_value, rx_mode_value_percent = map(list, zip(*sorted(zip(rx_mode, rx_mode_value_str, rx_mode_value, rx_mode_value_percent), key=length_sort)))

    logger.debug("After sort rx mode: {rx_mode} : {rx_mode_value_str} : {rx_mode_value} : {rx_mode_value_percent}".
                 format(rx_mode=rx_mode, rx_mode_value_str=rx_mode_value_str, rx_mode_value=rx_mode_value, rx_mode_value_percent=rx_mode_value_percent))

    rx_mode = [s.replace('v_rx_mode_', '') for s in rx_mode]
    rx_mode = [s.replace('AAA', '') for s in rx_mode]
    rx_mode = [s.replace('_', ' ') for s in rx_mode]
    rx_mode = [s.upper() for s in rx_mode]

    # rx_mode values
    report.set_table_title("RX Mode Histogram")
    report.build_table_title()

    df_rx_mode = pd.DataFrame({" RX Mode ": [k for k in rx_mode], " Total Packets ": [i for i in rx_mode_value],
                               " Percentage ": [j for j in rx_mode_value_percent]})

    report.set_table_dataframe(df_rx_mode)
    report.build_table()

    report.set_csv_filename("rx_mode.csv")
    report.write_dataframe_to_csv()

    # RX MODE
    graph = lf_bar_graph(_data_set=[rx_mode_value_percent],
                         _xaxis_name="RX Mode",
                         _yaxis_name="Percent Packets RX per Mode",
                         _xaxis_categories=rx_mode,
                         _graph_image_name="RX Mode",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(18, 7),
                         _grp_title='RX Mode',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve tx data from json for MODE
    tx_mode = []
    tx_mode_value_str = []
    tx_mode_value = []
    tx_mode_value_percent = []
    tx_mode_total_count = 0

    # TODO change value to count
    # retrieve each mode value from json
    for iterator in wifi_stats_json:
        if 'tx_mode' in iterator:
            tx_mode.append(iterator)
            tx_mode_value_str.append(str(wifi_stats_json[iterator]))
            tx_mode_value.append(wifi_stats_json[iterator])
            tx_mode_total_count += wifi_stats_json[iterator]

    if tx_mode_total_count == 0:
        logger.warning("Could not find any tx-mode packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for tx_mode_count in tx_mode_value:
            tx_mode_value_percent.append(0)
    else:
        # calculate percentages
        for tx_mode_count in tx_mode_value:
            tx_mode_value_percent.append(round((tx_mode_count / tx_mode_total_count) * 100, 2))

    # manipulate data to sort by length to have
    # CCK is first, the OFDMA, then HT variants, then VHT, the HE
    tx_mode = [s.replace('v_tx_mode_ht', 'v_tx_mode_ht_AAA') for s in tx_mode]
    tx_mode = [s.replace('v_tx_mode_vht', 'v_tx_mode_vht_AAA') for s in tx_mode]
    tx_mode = [s.replace('v_tx_mode_he', 'v_tx_mode_he_AAA') for s in tx_mode]

    # tx_mode.sort(key=length_sort)
    logger.debug("Before sort: {tx_mode} : {tx_mode_value_str} : {tx_mode_value} : {tx_mode_value_percent}".
                 format(tx_mode=tx_mode, tx_mode_value_str=tx_mode_value_str, tx_mode_value=tx_mode_value, tx_mode_value_percent=tx_mode_value_percent))

    # see rx_mcs for detales
    tx_mode, tx_mode_value_str, tx_mode_value, tx_mode_value_percent = map(list, zip(*sorted(zip(tx_mode, tx_mode_value_str, tx_mode_value, tx_mode_value_percent), key=length_sort)))

    logger.debug("After sort: {tx_mode} : {tx_mode_value_str} : {tx_mode_value} : {tx_mode_value_percent}".
                 format(tx_mode=tx_mode, tx_mode_value_str=tx_mode_value_str, tx_mode_value=tx_mode_value, tx_mode_value_percent=tx_mode_value_percent))

    tx_mode = [s.replace('v_tx_mode_', '') for s in tx_mode]
    tx_mode = [s.replace('AAA', '') for s in tx_mode]
    tx_mode = [s.replace('_', ' ') for s in tx_mode]
    tx_mode = [s.upper() for s in tx_mode]

    # tx_mode values
    report.set_table_title("TX Mode Histogram")
    report.build_table_title()

    df_tx_mode = pd.DataFrame({" TX Mode ": [k for k in tx_mode], " Total Packets ": [i for i in tx_mode_value],
                               " Percentage ": [j for j in tx_mode_value_percent]})

    report.set_table_dataframe(df_tx_mode)
    report.build_table()

    report.set_csv_filename("tx_mode.csv")
    report.write_dataframe_to_csv()

    # TX MODE
    graph = lf_bar_graph(_data_set=[tx_mode_value_percent],
                         _xaxis_name="TX Mode",
                         _yaxis_name="Percent Packets TX per Mode",
                         _xaxis_categories=tx_mode,
                         _graph_image_name="TX Mode",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='TX Mode',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve rx data from json for BW
    rx_bw = []
    rx_bw_value_str = []
    rx_bw_value = []
    rx_bw_value_percent = []
    rx_bw_total_count = 0

    # TODO change value to count
    # retrieve each nss value from json
    for iterator in wifi_stats_json:
        if 'rx_bw' in iterator:
            rx_bw.append(iterator)
            rx_bw_value_str.append(str(wifi_stats_json[iterator]))
            rx_bw_value.append(wifi_stats_json[iterator])
            rx_bw_total_count += wifi_stats_json[iterator]

    logger.debug("rx_bw: {rx_bw}".format(rx_bw=rx_bw))

    if rx_bw_total_count == 0:
        logger.warning("Could not find any rx-bw packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for rx_bw_count in rx_bw_value:
            rx_bw_value_percent.append(0)
    else:
        # calculate percentages
        for rx_bw_count in rx_bw_value:
            rx_bw_value_percent.append(round((rx_bw_count / rx_bw_total_count) * 100, 2))

    logger.debug("Before sort rx bw: {rx_bw} : {rx_bw_value_str} : {rx_bw_value} : {rx_bw_value_percent}".
                 format(rx_bw=rx_bw, rx_bw_value_str=rx_bw_value_str, rx_bw_value=rx_bw_value, rx_bw_value_percent=rx_bw_value_percent))

    # see rx_mcs for detales
    rx_bw, rx_bw_value_str, rx_bw_value, rx_bw_value_percent = map(list, zip(*sorted(zip(rx_bw, rx_bw_value_str, rx_bw_value, rx_bw_value_percent), key=num_sort)))

    logger.debug("After sort rx bw: {rx_bw} : {rx_bw_value_str} : {rx_bw_value} : {rx_bw_value_percent}".
                 format(rx_bw=rx_bw, rx_bw_value_str=rx_bw_value_str, rx_bw_value=rx_bw_value, rx_bw_value_percent=rx_bw_value_percent))

    # rx_bw.sort(key=num_sort)

    rx_bw = [s.replace('v_rx_bw_he_ru', 'HE RU') for s in rx_bw]

    rx_bw = [s.replace('v_rx_bw_', 'BW ') for s in rx_bw]

    # rx_bw values
    report.set_table_title("RX BW Histogram")
    report.build_table_title()

    df_rx_bw = pd.DataFrame({" RX BW ": [k for k in rx_bw], " Total Packets ": [i for i in rx_bw_value],
                             " Percentage ": [j for j in rx_bw_value_percent]})

    report.set_table_dataframe(df_rx_bw)
    report.build_table()

    report.set_csv_filename("rx_bw.csv")
    report.write_dataframe_to_csv()

    # RX BW
    graph = lf_bar_graph(_data_set=[rx_bw_value_percent],
                         _xaxis_name="RX BW",
                         _yaxis_name="Percent Packets RX per BW",
                         _xaxis_categories=rx_bw,
                         _graph_image_name="RX BW",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='RX BW',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve tx data from json for BW
    tx_bw = []
    tx_bw_value_str = []
    tx_bw_value = []
    tx_bw_value_percent = []
    tx_bw_total_count = 0

    # TODO change value to count
    # retrieve each nss value from json
    for iterator in wifi_stats_json:
        if 'tx_bw' in iterator:
            tx_bw.append(iterator)
            tx_bw_value_str.append(str(wifi_stats_json[iterator]))
            tx_bw_value.append(wifi_stats_json[iterator])
            tx_bw_total_count += wifi_stats_json[iterator]
    if tx_bw_total_count == 0:
        logger.warning("Could not find any tx-bw packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for tx_bw_count in tx_bw_value:
            tx_bw_value_percent.append(0)
    else:
        # calculate percentages
        for tx_bw_count in tx_bw_value:
            tx_bw_value_percent.append(round((tx_bw_count / tx_bw_total_count) * 100, 2))

    logger.debug("Before sort tx bw: {tx_bw} : {tx_bw_value_str} : {tx_bw_value} : {tx_bw_value_percent}".
                 format(tx_bw=tx_bw, tx_bw_value_str=tx_bw_value_str, tx_bw_value=tx_bw_value, tx_bw_value_percent=tx_bw_value_percent))

    # see rx_mcs for detales
    tx_bw, tx_bw_value_str, tx_bw_value, tx_bw_value_percent = map(list, zip(*sorted(zip(tx_bw, tx_bw_value_str, tx_bw_value, tx_bw_value_percent), key=num_sort)))

    logger.debug("After sort tx bw: {tx_bw} : {tx_bw_value_str} : {tx_bw_value} : {tx_bw_value_percent}".
                 format(tx_bw=tx_bw, tx_bw_value_str=tx_bw_value_str, tx_bw_value=tx_bw_value, tx_bw_value_percent=tx_bw_value_percent))

    # tx_bw.sort(key=num_sort)

    tx_bw = [s.replace('v_tx_bw_', 'BW ') for s in tx_bw]

    # tx_bw values
    report.set_table_title("TX BW Histogram")
    report.build_table_title()

    df_tx_bw = pd.DataFrame({"TX BW": [k for k in tx_bw], " Total Packets ": [i for i in tx_bw_value],
                             " Percentage ": [j for j in tx_bw_value_percent]})

    report.set_table_dataframe(df_tx_bw)
    report.build_table()

    report.set_csv_filename("tx_bw.csv")
    report.write_dataframe_to_csv()

    # TX BW
    graph = lf_bar_graph(_data_set=[tx_bw_value_percent],
                         _xaxis_name="TX BW",
                         _yaxis_name="Percent Packets TX per BW",
                         _xaxis_categories=tx_bw,
                         _graph_image_name="TX BW",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='TX BW',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve rx data from json for NSS
    rx_nss = []
    rx_nss_value_str = []
    rx_nss_value = []
    rx_nss_value_percent = []
    rx_nss_total_count = 0

    # TODO change value to count
    # retrieve each nss value from json
    for iterator in wifi_stats_json:
        if 'rx_nss' in iterator:
            rx_nss.append(iterator)
            rx_nss_value_str.append(str(wifi_stats_json[iterator]))
            rx_nss_value.append(wifi_stats_json[iterator])
            rx_nss_total_count += wifi_stats_json[iterator]
    if rx_nss_total_count == 0:
        logger.warning("Could not find any rx-nss packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for rx_nss_count in rx_nss_value:
            rx_nss_value_percent.append(0)
    else:
        # calculate percentages
        for rx_nss_count in rx_nss_value:
            rx_nss_value_percent.append(round((rx_nss_count / rx_nss_total_count) * 100, 2))

    rx_nss = [s.replace('v_rx_nss_1', '1 x 1') for s in rx_nss]
    rx_nss = [s.replace('v_rx_nss_2', '2 x 2') for s in rx_nss]
    rx_nss = [s.replace('v_rx_nss_3', '3 x 3') for s in rx_nss]
    rx_nss = [s.replace('v_rx_nss_4', '4 x 4') for s in rx_nss]

    # rx_nss values
    report.set_table_title("RX NSS Histogram")
    report.build_table_title()

    df_rx_nss = pd.DataFrame({" RX NSS ": [k for k in rx_nss], " Total Packets ": [i for i in rx_nss_value],
                              " Percentage ": [j for j in rx_nss_value_percent]})

    report.set_table_dataframe(df_rx_nss)
    report.build_table()

    report.set_csv_filename("rx_nss.csv")
    report.write_dataframe_to_csv()

    # RX NSS
    graph = lf_bar_graph(_data_set=[rx_nss_value_percent],
                         _xaxis_name="RX NSS",
                         _yaxis_name="Percent RX Packets of NSS",
                         _xaxis_categories=rx_nss,
                         _graph_image_name="RX NSS",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='RX NSS',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve tx data from json for NSS
    tx_nss = []
    tx_nss_value_str = []
    tx_nss_value = []
    tx_nss_value_percent = []
    tx_nss_total_count = 0

    # TODO change value to count
    # retrieve each nss value from json
    for iterator in wifi_stats_json:
        if 'tx_nss' in iterator:
            tx_nss.append(iterator)
            tx_nss_value_str.append(str(wifi_stats_json[iterator]))
            tx_nss_value.append(wifi_stats_json[iterator])
            tx_nss_total_count += wifi_stats_json[iterator]
    if tx_nss_total_count == 0:
        logger.warning("Could not find any tx-nss packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for tx_nss_count in tx_nss_value:
            tx_nss_value_percent.append(0)
    else:
        # calculate percentages
        for tx_nss_count in tx_nss_value:
            tx_nss_value_percent.append(round((tx_nss_count / tx_nss_total_count) * 100, 2))

    tx_nss = [s.replace('v_tx_nss_1', '1 x 1') for s in tx_nss]
    tx_nss = [s.replace('v_tx_nss_2', '2 x 2') for s in tx_nss]
    tx_nss = [s.replace('v_tx_nss_3', '3 x 3') for s in tx_nss]
    tx_nss = [s.replace('v_tx_nss_4', '4 x 4') for s in tx_nss]

    # tx_nss values
    report.set_table_title("TX NSS Histogram")
    report.build_table_title()

    df_tx_nss = pd.DataFrame({" TX NSS ": [k for k in tx_nss], " Total Packets ": [i for i in tx_nss_value],
                              " Percentage ": [j for j in tx_nss_value_percent]})

    report.set_table_dataframe(df_tx_nss)
    report.build_table()

    report.set_csv_filename("tx_nss.csv")
    report.write_dataframe_to_csv()

    # TX NSS
    graph = lf_bar_graph(_data_set=[tx_nss_value_percent],
                         _xaxis_name="TX NSS",
                         _yaxis_name="Percent TX Packets of NSS",
                         _xaxis_categories=tx_nss,
                         _graph_image_name="TX NSS",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='TX NSS',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve rx data from json for MCS
    rx_mcs = []
    rx_mcs_value_str = []
    rx_mcs_value = []
    rx_mcs_value_percent = []
    rx_mcs_total_count = 0

    # TODO change value to count
    # retrieve each mcs value from json
    for iterator in wifi_stats_json:
        if 'rx_mcs' in iterator:
            rx_mcs.append(iterator)
            rx_mcs_value_str.append(str(wifi_stats_json[iterator]))
            rx_mcs_value.append(wifi_stats_json[iterator])
            rx_mcs_total_count += wifi_stats_json[iterator]

    if rx_mcs_total_count == 0:
        logger.warning("Could not find any rx-mode packets.")
        logger.info(pformat(wifi_stats_json))
        # calculate percentages
        for rx_mcs_count in rx_mcs_value:
            rx_mcs_value_percent.append(0)
    else:
        # calculate percentages
        for rx_mcs_count in rx_mcs_value:
            rx_mcs_value_percent.append(round((rx_mcs_count / rx_mcs_total_count) * 100, 2))

    logger.info("Before sort rx MCS {rx_mcs} : {rx_mcs_value_str} : {rx_mcs_value} : {rx_mcs_value_percent}".
                format(rx_mcs=rx_mcs, rx_mcs_value_str=rx_mcs_value_str, rx_mcs_value=rx_mcs_value, rx_mcs_value_percent=rx_mcs_value_percent))

    #
    zip_rx_mcs = zip(rx_mcs, rx_mcs_value_str, rx_mcs_value, rx_mcs_value_percent)

    # https://stackoverflow.com/questions/19931975/sort-multiple-lists-simultaneously
    # https://www.geeksforgeeks.org/sorted-function-python/
    # use the rx_mcs as the sort key
    # Using the tuples default ordering
    zip_rx_mcs_sort = sorted(zip_rx_mcs, key=num_sort)

    # https://www.geeksforgeeks.org/python-unzip-a-list-of-tuples/
    res_mcs = zip(*zip_rx_mcs_sort)

    # return the sorted lists
    rx_mcs, rx_mcs_value_str, rx_mcs_value, rx_mcs_value_percent = map(list, res_mcs)

    logger.info("After sort rx MCS {rx_mcs} : {rx_mcs_value_str} : {rx_mcs_value} : {rx_mcs_value_percent}".
                format(rx_mcs=rx_mcs, rx_mcs_value_str=rx_mcs_value_str, rx_mcs_value=rx_mcs_value, rx_mcs_value_percent=rx_mcs_value_percent))

    rx_mcs = [s.replace('v_rx_mcs_', 'MCS ') for s in rx_mcs]

    # the above could be done with this one command
    # rx_mcs, rx_mcs_value_str, rx_mcs_value = map(list, zip(*sorted(zip(rx_mcs,rx_mcs_value_str,rx_mcs_value),key=num_sort)))

    # rx_mcs values
    report.set_table_title("RX MCS Histogram")
    report.build_table_title()

    df_rx_mcs = pd.DataFrame({" RX MCS ": [k for k in rx_mcs], " Total Packets ": [i for i in rx_mcs_value],
                              " Percentage ": [j for j in rx_mcs_value_percent]})

    report.set_table_dataframe(df_rx_mcs)
    report.build_table()

    report.set_csv_filename("rx_mcs.csv")
    report.write_dataframe_to_csv()

    # RX MCS encoding
    graph = lf_bar_graph(_data_set=[rx_mcs_value_percent],
                         _xaxis_name="RX MCS encoding",
                         _yaxis_name="Percent RX Packets per MCS encoding",
                         _xaxis_categories=rx_mcs,
                         _graph_image_name="RX MCS encoding",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='RX MCS encoding',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve tx  mcs value from json
    tx_mcs = []
    tx_mcs_value_str = []
    tx_mcs_value = []
    tx_mcs_value_percent = []
    tx_mcs_total_count = 0

    for iterator in wifi_stats_json:
        if 'tx_mcs' in iterator:
            tx_mcs.append(iterator)
            tx_mcs_value_str.append(str(wifi_stats_json[iterator]))
            tx_mcs_value.append(wifi_stats_json[iterator])
            tx_mcs_total_count += wifi_stats_json[iterator]

    # calculate percentages
    for tx_mcs_count in tx_mcs_value:
        if tx_mcs_total_count == 0:
            tx_mcs_value_percent.append(0)
        else:
            tx_mcs_value_percent.append(round((tx_mcs_count / tx_mcs_total_count) * 100, 2))

    logger.debug("Before sort tx MCS: {tx_mcs} : {tx_mcs_value_str} : {tx_mcs_value} : {tx_mcs_value_percent}".
                 format(tx_mcs=tx_mcs, tx_mcs_value_str=tx_mcs_value_str, tx_mcs_value=tx_mcs_value, tx_mcs_value_percent=tx_mcs_value_percent))

    # see rx_mcs for details
    tx_mcs, tx_mcs_value_str, tx_mcs_value, tx_mcs_value_percent = map(list, zip(*sorted(zip(tx_mcs, tx_mcs_value_str, tx_mcs_value, tx_mcs_value_percent), key=num_sort)))

    logger.debug("After sort tx MCS: {tx_mcs} : {tx_mcs_value_str} : {tx_mcs_value} : {tx_mcs_value_percent}".
                 format(tx_mcs=tx_mcs, tx_mcs_value_str=tx_mcs_value_str, tx_mcs_value=tx_mcs_value, tx_mcs_value_percent=tx_mcs_value_percent))

    # tx_mcs.sort(key=num_sort)

    tx_mcs = [s.replace('v_tx_mcs_', 'MCS ') for s in tx_mcs]

    # tx_mcs values
    report.set_table_title("TX MCS Histogram")
    report.build_table_title()

    df_tx_mcs = pd.DataFrame({" TX MCS ": [k for k in tx_mcs], " Total Packets ": [i for i in tx_mcs_value],
                              " Percentage ": [j for j in tx_mcs_value_percent]})

    report.set_table_dataframe(df_tx_mcs)
    report.build_table()

    report.set_csv_filename("tx_mcs.csv")
    report.write_dataframe_to_csv()

    # TX MCS encoding
    graph = lf_bar_graph(_data_set=[tx_mcs_value_percent],
                         _xaxis_name="TX MCS encoding",
                         _yaxis_name="Percentage Received Packets with MCS encoding",
                         _xaxis_categories=tx_mcs,
                         _graph_image_name="TX MCS encoding",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='TX MCS encoding',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve rx data from json for ampdu
    rx_ampdu = []
    rx_ampdu_value_str = []
    rx_ampdu_value = []
    rx_ampdu_value_percent = []
    rx_ampdu_total_count = 0

    # TODO change value to count
    # retrieve each mcs value from json
    for iterator in wifi_stats_json:
        if 'rx_ampdu' in iterator:
            rx_ampdu.append(iterator)
            rx_ampdu_value_str.append(str(wifi_stats_json[iterator]))
            rx_ampdu_value.append(wifi_stats_json[iterator])
            rx_ampdu_total_count += wifi_stats_json[iterator]

    logger.debug("rx_ampdu: {rx_ampdu}".format(rx_ampdu=rx_ampdu))

    logger.debug("Before sort rx AMPDU: {rx_ampdu} : {rx_ampdu_value_str} : {rx_ampdu_value}".
                 format(rx_ampdu=rx_ampdu, rx_ampdu_value_str=rx_ampdu_value_str, rx_ampdu_value=rx_ampdu_value))

    # see rx_mcs for detales
    rx_ampdu, rx_ampdu_value_str, rx_ampdu_value = map(list, zip(*sorted(zip(rx_ampdu, rx_ampdu_value_str, rx_ampdu_value), key=num_sort)))

    logger.debug("After sort rx AMPDU: {rx_ampdu} : {rx_ampdu_value_str} : {rx_ampdu_value}".
                 format(rx_ampdu=rx_ampdu, rx_ampdu_value_str=rx_ampdu_value_str, rx_ampdu_value=rx_ampdu_value))

    # rx_ampdu.sort(key=num_sort)

    rx_ampdu = [s.replace('rx_ampdu_len_', '') for s in rx_ampdu]
    rx_ampdu = [s.replace('_', '-') for s in rx_ampdu]

    logger.debug("rx_ampdu: {rx_ampdu}".format(rx_ampdu=rx_ampdu))

    # use class

    # calculate percentages
    for rx_ampdu_count in rx_ampdu_value:
        if rx_ampdu_total_count == 0:
            rx_ampdu_value_percent.append(0)
        else:
            rx_ampdu_value_percent.append(round((rx_ampdu_count / rx_ampdu_total_count) * 100, 2))

    # rx_ampdu values
    report.set_table_title("Packets RX with AMPDU Count")
    report.build_table_title()

    df_rx_ampdu = pd.DataFrame({" RX AMPDU ": [k for k in rx_ampdu], " Total Packets ": [i for i in rx_ampdu_value],
                                " Percentage ": [j for j in rx_ampdu_value_percent]})

    report.set_table_dataframe(df_rx_ampdu)
    report.build_table()

    report.set_csv_filename("rx_ampdu.csv")
    report.write_dataframe_to_csv()

    # RX ampdu encoding
    graph = lf_bar_graph(_data_set=[rx_ampdu_value_percent],
                         _xaxis_name="RX ampdu",
                         _yaxis_name="Percent Packets RX with AMPDU Count",
                         _xaxis_categories=rx_ampdu,
                         _graph_image_name="RX AMPDU Count",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='RX ampdu',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve tx ampdu value from json
    tx_ampdu = []
    tx_ampdu_value_str = []
    tx_ampdu_value = []
    tx_ampdu_value_percent = []
    tx_ampdu_total_count = 0

    for iterator in wifi_stats_json:
        if 'tx_ampdu' in iterator:
            tx_ampdu.append(iterator)
            tx_ampdu_value_str.append(str(wifi_stats_json[iterator]))
            tx_ampdu_value.append(wifi_stats_json[iterator])
            tx_ampdu_total_count += wifi_stats_json[iterator]

    # calculate percentages
    for tx_ampdu_count in tx_ampdu_value:
        if tx_ampdu_total_count == 0:
            tx_ampdu_value_percent.append(0)
        else:
            tx_ampdu_value_percent.append(round((tx_ampdu_count / tx_ampdu_total_count) * 100, 2))

    logger.debug(tx_ampdu)

    logger.debug("Before sort tx AMPDU: {tx_ampdu} : {tx_ampdu_value_str} : {tx_ampdu_value}".
                 format(tx_ampdu=tx_ampdu, tx_ampdu_value_str=tx_ampdu_value_str, tx_ampdu_value=tx_ampdu_value))

    # see rx_mcs for detales
    tx_ampdu, tx_ampdu_value_str, tx_ampdu_value = map(list, zip(*sorted(zip(tx_ampdu, tx_ampdu_value_str, tx_ampdu_value), key=num_sort)))

    logger.debug("After sort tx AMPDU: {tx_ampdu} : {tx_ampdu_value_str} : {tx_ampdu_value}".
                 format(tx_ampdu=tx_ampdu, tx_ampdu_value_str=tx_ampdu_value_str, tx_ampdu_value=tx_ampdu_value))

    # tx_ampdu.sort(key=num_sort)
    tx_ampdu = [s.replace('tx_ampdu_len_', '') for s in tx_ampdu]
    tx_ampdu = [s.replace('_', '-') for s in tx_ampdu]

    logger.debug("tx_ampdu: {tx_ampdu}".format(tx_ampdu=tx_ampdu))

    # tx_ampdu values
    report.set_table_title("Percent Packets TX with AMPDU Count")
    report.build_table_title()

    df_tx_ampdu = pd.DataFrame({" TX AMPDU ": [k for k in tx_ampdu], " Total Packets ": [i for i in tx_ampdu_value],
                                " Percentage ": [j for j in tx_ampdu_value_percent]})

    report.set_table_dataframe(df_tx_ampdu)
    report.build_table()

    report.set_csv_filename("tx_ampdu.csv")
    report.write_dataframe_to_csv()

    # TX ampdu
    graph = lf_bar_graph(_data_set=[tx_ampdu_value_percent],
                         _xaxis_name="TX ampdu",
                         _yaxis_name="Percent Packets TX with AMPDU Count",
                         _xaxis_categories=tx_ampdu,
                         _graph_image_name="TX ampdu encoding",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='TX ampdu',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # retrieve tx msdu value from json
    tx_msdu = []
    tx_msdu_value_str = []
    tx_msdu_value = []
    tx_msdu_value_percent = []
    tx_msdu_total_count = 0

    for iterator in wifi_stats_json:
        if 'tx_msdu' in iterator:
            tx_msdu.append(iterator)
            tx_msdu_value_str.append(str(wifi_stats_json[iterator]))
            tx_msdu_value.append(wifi_stats_json[iterator])
            tx_msdu_total_count += wifi_stats_json[iterator]

    # calculate percentages
    for tx_msdu_count in tx_msdu_value:
        if tx_msdu_total_count == 0:
            tx_msdu_value_percent.append(0)
        else:
            tx_msdu_value_percent.append(round((tx_msdu_count / tx_msdu_total_count) * 100, 2))

    tx_msdu = [s.replace('tx_msdu_pack_', '') for s in tx_msdu]

    # tx_msdu values
    report.set_table_title("TX MSDU Histogram")
    report.build_table_title()

    df_tx_msdu = pd.DataFrame({" TX MSDU ": [k for k in tx_msdu], " Total Packets ": [i for i in tx_msdu_value],
                               " Percentage ": [j for j in tx_msdu_value_percent]})

    report.set_table_dataframe(df_tx_msdu)
    report.build_table()

    report.set_csv_filename("tx_msdu.csv")
    report.write_dataframe_to_csv()

    # TX msdu
    graph = lf_bar_graph(_data_set=[tx_msdu_value_percent],
                         _xaxis_name="TX MSDU",
                         _yaxis_name="Percent Packets TX per MSDU",
                         _xaxis_categories=tx_msdu,
                         _graph_image_name="TX MSDU",
                         _label=["% Total Packets"],
                         _color=['blue'],
                         _color_edge='black',
                         _figsize=(17, 7),
                         _grp_title='TX msdu',
                         _xaxis_step=1,
                         _show_bar_value=True,
                         _text_font=7,
                         _text_rotation=45,
                         _xticks_font=7,
                         _legend_loc="best",
                         _legend_box=(1, 1),
                         _legend_ncol=1,
                         _legend_fontsize=None,
                         _enable_csv=False)

    graph_png = graph.build_bar_graph()
    report.set_graph_image(graph_png)
    report.move_graph_image()
    report.build_graph()

    # Finish the report
    report.build_footer()
    report.copy_js()

    report.write_html_with_timestamp()
    report.write_index_html()

    if platform.system() == 'Linux':
        report.write_pdf_with_timestamp(_page_size='A4', _orientation='Landscape')


if __name__ == "__main__":
    main()
