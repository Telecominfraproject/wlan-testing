name: nightly build
env:
  # thirdparties
  DOCKER_SERVER: tip-tip-wlan-cloud-docker-repo.jfrog.io
  DOCKER_USER_NAME: wlan-testing-cicd
  DOCKER_USER_PASSWORD: ${{ secrets.DOCKER_USER_PASSWORD }}
  # AWS credentials
  AWS_EKS_NAME: tip-wlan-main
  AWS_DEFAULT_OUTPUT: json
  AWS_DEFAULT_REGION: us-east-2
  AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_CLIENT_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_CLIENT_KEY }}
  # Cloud SDK certs
  CACERT: ${{ secrets.CACERT }}
  CAKEY: ${{ secrets.CAKEY }}
  ALLURE_CLI_VERSION: 2.14.0

on:
  workflow_dispatch:
  push:
  #schedule:
  #- cron: '15 0 * * *'

defaults:
  run:
    shell: bash

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    # checkout needed repositories
    - name: Checkout Testing repo
      uses: actions/checkout@v2
      with:
        path: wlan-testing

    - name: Checkout LANforge scripts
      uses: actions/checkout@v2
      with:
        path: wlan-lanforge-scripts
        repository: Telecominfraproject/wlan-lanforge-scripts

    - name: import LANforge scripts
      working-directory: wlan-testing
      run: ./sync_repos.bash

    - name: create configuration.py
      working-directory: wlan-testing
      run: |
        cat << EOF > configuration.py
        ${{ secrets.LAB_CONFIGURATION }}
        EOF

    - name: create Dockerfile
      working-directory: wlan-testing
      run: |
        cat << EOF > Dockerfile
        FROM python:3.8

        RUN mkdir ~/.pip
        RUN echo "[global]" > ~/.pip/pip.conf
        RUN echo "index-url = https://pypi.org/simple" >> ~/.pip/pip.conf
        RUN echo "extra-index-url = https://tip-read:tip-read@tip.jfrog.io/artifactory/api/pypi/tip-wlan-python-pypi-local/simple" >> ~/.pip/pip.conf
        RUN pip3 install pytest==6.2.2 allure-pytest bs4 paramiko xlsxwriter requests pandas influxdb influxdb-client tip-wlan-cloud scp
        COPY lanforge /wlan-testing/lanforge
        COPY tests /wlan-testing/tests
        COPY libs /wlan-testing/libs
        COPY configuration.py /wlan-testing/tests/configuration.py

        WORKDIR /wlan-testing
        ENTRYPOINT ["bash"]
        EOF

    # build and push docker image
    - name: docker login
      run: docker login ${{ env.DOCKER_SERVER }} -u ${{ env.DOCKER_USER_NAME }} -p ${{ env.DOCKER_USER_PASSWORD }}
    - name: build docker image
      working-directory: wlan-testing
      run: docker build -t ${{ env.DOCKER_SERVER }}/cloud-sdk-nightly:pytest-${{ github.run_number }} .
    - name: push docker image
      run: docker push ${{ env.DOCKER_SERVER }}/cloud-sdk-nightly:pytest-${{ github.run_number }}

#  cloudsdk:
#    runs-on: ubuntu-latest
#    steps:
#    - name: Checkout pki scripts repo
#      uses: actions/checkout@v2
#      with:
#        path: wlan-pki
#        repository: Telecominfraproject/wlan-pki-cert-scripts
#    - name: Checkout Cloud SDK repo
#      uses: actions/checkout@v2
#      with:
#        path: wlan-helm
#        repository: Telecominfraproject/wlan-cloud-helm
#    - name: Checkout helm values repo
#      uses: actions/checkout@v2
#      with:
#        path: toolsmith
#        repository: Telecominfraproject/Toolsmith
#        token: ${{ secrets.PAT_TOKEN }}
#
#    - name: Prepare environment
#      run: |
#        mkdir -p ./wlan-pki/testCA/private
#        mkdir -p ./wlan-pki/testCA/newcerts
#        mkdir -p ./wlan-pki/generated
#        touch ./wlan-pki/testCA/index.txt
#        echo "01" > ./wlan-pki/testCA/serial.txt
#        echo "${{ env.CACERT }}" | base64 -d > ./wlan-pki/testCA/cacert.pem
#        echo "${{ env.CAKEY }}" | base64 -d > ./wlan-pki/testCA/private/cakey.pem
#        cp ./toolsmith/helm-values/aws-cicd.yaml ./wlan-helm/tip-wlan/resources/environments/aws-cicd.yaml
#
#    - name: Generate certs
#      run: |
#        cd ./wlan-pki
#        ./generate_all.sh true
#        ./copy-certs-to-helm.sh "../wlan-helm"
#
#    - name: Deploy Cloud SDK
#      run: |
#        cd ./wlan-helm/tip-wlan
#        aws eks update-kubeconfig  --name ${{ env.AWS_EKS_NAME }}
#        # start deployment
#        helm dependency update
#        helm upgrade --install tip . -f resources/environments/aws-cicd.yaml --create-namespace --namespace tip
#
#    - name: Show pod state on deployment failure
#      if: failure()
#      run: |
#        kubectl get pods -n tip
#        kubectl describe pods -n tip

  test:
    runs-on: ubuntu-latest
#    needs: [ build, cloudsdk ]
    needs: [ build ]
    steps:
    - name: get EKS access credentials
      run: aws eks update-kubeconfig  --name ${{ env.AWS_EKS_NAME }}

    - name: install Allure CLI tool
      run: |
        wget https://repo.maven.apache.org/maven2/io/qameta/allure/allure-commandline/${{ env.ALLURE_CLI_VERSION }}/allure-commandline-${{ env.ALLURE_CLI_VERSION }}.tgz
        tar -xzf allure-commandline-${{ env.ALLURE_CLI_VERSION }}.tgz

    - name: set job name
      id: job
      run: echo "::set-output name=name::nightly-ci-${{ github.run_number }}"

    - name: run sanity tests
      run: |
        cat <<EOF | kubectl apply -f -
        apiVersion: batch/v1
        kind: Job
        metadata:
          name: "${{ steps.job.outputs.name }}"
        spec:
          template:
            spec:
              containers:
              - name: tests
                image: ${{ env.DOCKER_SERVER }}/cloud-sdk-nightly:pytest-${{ github.run_number }}
                command: [ "bash" ]
                args: 
                - "-c"
                - "cd tests; pytest -m sanity -s -vvv --testbed=basic-02 --skip-testrail --alluredir=/tmp/allure-results; sleep 60"
              imagePullSecrets:
              - name: tip-docker-registry-key
              restartPolicy: Never
          backoffLimit: 0
        EOF

        sleep 60 # wait for the pod to come up

        #echo "waiting for tests to complete"
        #kubectl wait --for=condition=complete --timeout=90m "job/${{ steps.job.outputs.name }}"
        podname=$(kubectl get pods --no-headers -o custom-columns=":metadata.name" -l job-name="${{ steps.job.outputs.name }}" | sed "s/pod\///")

        until [ -s test_everything.xml ]
        do
          echo "waiting for tests to complete"
          kubectl cp $podname:/wlan-testing/tests/test_everything.xml test_everything.xml
          sleep 10
        done

        kubectl cp $podname:/tmp/allure-results allure-results

    - name: print logs
      if: ${{ always() }}
      run: |
        podname=$(kubectl get pods --no-headers -o custom-columns=":metadata.name" -l job-name="${{ steps.job.outputs.name }}" | sed "s/pod\///")
        kubectl logs $podname
        # try to match pytest result output
        # kubectl logs $podname | egrep -v -q '[[:digit:]]* failed'

    - name: upload Allure results as artifact
      if: ${{ always() }}
      uses: actions/upload-artifact@v2
      with:
        name: allure-results
        path: allure-results

    - name: generate Allure report
      if: ${{ always() }}
      run: allure-${{ env.ALLURE_CLI_VERSION }}/bin/allure generate

    - name: upload Allure report as artifact
      if: ${{ always() }}
      uses: actions/upload-artifact@v2
      with:
        name: allure-report
        path: allure-report

    - name: cleanup
      if: ${{ always() }}
      run: |
        kubectl delete job "${{ steps.job.outputs.name }}" --wait=true --ignore-not-found=true
#    - name: Publish Unit Test Results
#      uses: EnricoMi/publish-unit-test-result-action@v1.7
#      with:
#        github_token: ${{ secrets.GITHUB_TOKEN }}
#        files: "**/*.xml"
